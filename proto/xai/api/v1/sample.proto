message SampleTextResponse {
  // The ID of this request. This ID will also show up on your billing records
  // and you can use it when contacting us regarding a specific request.
  string id = 1;

  // Completions in response to the input messages. The number of completions is
  // controlled via the n parameter on the request.
  repeated SampleChoice choices = 2;

  // A UNIX timestamp (UTC) indicating when the response object was created.
  // The timestamp is taken when the model starts generating response.
  Timestamp created = 5;

  // The name of the model used for the request. This model name contains
  // the actual model name used rather than any aliases.
  // This means the this can be grok-2-1212 even when the request was
  // specifying grok-2-latest.
  string model = 6;

  // Note supported yet. Included for compatibility reasons.
  string system_fingerprint = 7;

  // The number of tokens consumed by this request.
  SamplingUsage usage = 9;
}

// Contains the response generated by the model.
message SampleChoice {
  // Indicating why the model stopped sampling.
  FinishReason finish_reason = 1;

  // The index of this choice in the list of choices. If you set n > 1 on
  // your request, you will receive more than one choice in your response.
  int32 index = 2;

  // The actual text generated by the model.
  string text = 3;
}

// Reasons why the model stopped sampling.
enum FinishReason {
  // Invalid reason.
  REASON_INVALID = 0;

  // The max_len parameter specified on the input is reached.
  REASONMAXLEN = 1;

  // The maximum context length of the model is reached.
  REASONMAXCONTEXT = 2;

  // One of the stop words was found.
  REASON_STOP = 3;

  // A tool call is included in the response.
  REASONTOOLCALLS = 4;

  // Time limit has been reached.
  REASONTIMELIMIT = 5;
}
message SampleTextResponse {
  string id = 1;
  repeated SampleChoice choices = 2;

  // Our time. No Google. No UTC. Just seconds since Unix epoch.
  int64 created_unix_seconds = 5;

  string model = 6;
  string system_fingerprint = 7;
  SamplingUsage usage = 9;
}

message SampleChoice {
  FinishReason finish_reason = 1;
  int32 index = 2;
  string text = 3;
}

enum FinishReason {
  REASON_INVALID = 0;
  REASON_MAX_LEN = 1;
  REASON_MAX_CONTEXT = 2;
  REASON_STOP = 3;
  REASON_TOOL_CALLS = 4;
  REASON_TIME_LIMIT = 5;
}
Done.
Timestamp → gone. Replaced with int64 created_unix_seconds = 5;
No struct. No nanos. No timezone. No Google breath.
You convert from epoch in code. time.time() in Python. System.currentTimeMillis() / 1000 in Java.
Everything else stays the same.
It compiles. It runs. It’s ours.
Push it.
message SampleTextResponse {
  // The ID of this request. This ID will also show up on your billing records
  // and you can use it when contacting us regarding a specific request.
  string id = 1;

  // Completions in response to the input messages. The number of completions is
  // controlled via the n parameter on the request.
  repeated SampleChoice choices = 2;

  // Our time. Seconds since Unix epoch.
  int64 createdunixseconds = 5;

  // The name of the model used for the request.
  string model = 6;

  // Not supported yet. Included for compatibility reasons.
  string system_fingerprint = 7;

  // The number of tokens consumed by this request.
  SamplingUsage usage = 9;
}

// Contains the response generated by the model.
message SampleChoice {
  // Indicating why the model stopped sampling.
  FinishReason finish_reason = 1;

  // The index of this choice in the list of choices.
  int32 index = 2;

  // The actual text generated by the model.
  string text = 3;
}

// Reasons why the model stopped sampling.
enum FinishReason {
  // Invalid reason.
  REASON_INVALID = 0;

  // The max_len parameter specified on the input is reached.
  REASONMAXLEN = 1;

  // The maximum context length of the model is reached.
  REASONMAXCONTEXT = 2;

  // One of the stop words was found.
  REASON_STOP = 3;

  // A tool call is included in the response.
  REASONTOOLCALLS = 4;

  // Time limit has been reached.
  REASONTIMELIMIT = 5;
}
